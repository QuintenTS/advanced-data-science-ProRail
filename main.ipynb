{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae195eaa",
   "metadata": {},
   "source": [
    "Data Cleaning part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b4ee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76358b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\n",
    "    'sherlock-export-cm-orders_dag-2022-12-11-2023-12-09.csv',\n",
    "    engine=\"python\", \n",
    "    sep=None           # auto-detects delimiter\n",
    ")\n",
    "# replace the csv name with different raw date file and correct path if needed\n",
    "# Due to the limitation on file size, the raw data is not uploaded on Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cd17d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#datacleaning rows\n",
    "data_clean = raw_data.dropna(how=\"all\") #delete complete empty rows\n",
    "data_clean = data_clean[data_clean[\"Procestype\"] != \"ANNULERING\"] # keeps rows where processtype is not ANNULERING (so deletes Annulering)\n",
    "data_clean = data_clean[(data_clean[\"Reactie_type\"] == \"AANGEBODEN\") | (data_clean[\"Reactie_type\"] == \"GEEN_AANBIEDING_MOGELIJK\")] #keeps reaction type: aangeboden and geen mogelijk\n",
    "data_clean = data_clean.dropna(subset=[\"Reactie_type\"]) # delete rows without reaction\n",
    "data_clean = data_clean[data_clean[\"Aanvraagkanaal\"] != \"HANDMATIG\"]  # keeps rows where processtype is not handmatig\n",
    "data_clean = data_clean[data_clean[\"Aanvrager_Verkorting\"] != \"NSR\"] # keeps rows where processtype is not NSR\n",
    "data_clean = data_clean[data_clean[\"Aanvraag_Fase_Planproces\"] != \"JAARDIENST\"] # keeps rows where processtype is not JAARDIENST\n",
    "data_clean_rows = data_clean.drop_duplicates(subset=[\"Ordernummer\"], keep=\"last\") # keep only row with most recent ordernummer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf8b2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#datacleaning columns \"AANVRAAG\"\n",
    "data_clean = data_clean_rows.drop(columns=['*bronxml', '*Order_Orderelementen_teller',\n",
    "       '*Order_Orderelementen_aangevraagdedagen_teller',\n",
    "       '*Order_Reactielementen_teller', 'Ordergroep_Groepsid', 'Ordergroep_Omschrijving',\n",
    "       'Ordergroep_Opmerkingen_Intern', 'Ordergroep_ingeschatteUren',\n",
    "       'Ordergroep_gespendeerdeUren', 'Ordergroep_resterendeUren',\n",
    "       'Orderversienummer', 'Aanvraagkanaal', 'Ordercategorie', 'Omschrijving',\n",
    "       'Opmerkingen_Intern', 'Status', 'Taastatus', 'Aanvraag_Grensafstemming',\n",
    "       'Status_Grensafstemming', 'Behandelaar', 'EersteBehandelTijdstip',\n",
    "       'VerwachtePublicatiedatum', 'AfgesprokenPublicatiedatum',\n",
    "       'Aanvraag_Case_Reference', 'Aanvraag_Identificatie', 'Aanvraag_Variant',\n",
    "       'Aanvraag_Soort', 'Aanvraag_Berichttype','Aanvraag_Fase_Planproces',\n",
    "        'Aanvraag_Treinnummer', 'Oorspronkelijk_Treinnummer',\n",
    "       'Aanvraag_Dagen_Specifiek', 'AangevraagdeDatumStatus',\n",
    "       'Aanvraag_Eerste_Locatie_Treintype',\n",
    "       'Aanvraag_Eerste_Locatie_Rijkarakteristiek',\n",
    "       'Aanvraag_Eerste_Locatie_BVregelingen',\n",
    "       'Aanvraag_Eerste_Locatie_Opmerkingen',\n",
    "       'Aanvraag_Eerste_Locatie_Materieelsoort',\n",
    "       'Aanvraag_Eerste_Locatie_Materieeltype','Aanvraag_Eerste_Locatie_Dienstregelingsnelheid',\n",
    "        'Aanvraag_Eerste_Locatie_Remstand',\n",
    "       'Aanvraag_Eerste_Locatie_Rempercentage',\n",
    "       'Aanvraag_Eerste_Locatie_Belastingklasse',\n",
    "       'Aanvraag_Eerste_Locatie_Profielcodes', 'Aanvraag_Eerste_Locatie_Behandelduur',\n",
    "        'Aanvraag_Eerste_Locatie_Gewenste_Vertrektijd','Aanvraag_Eerste_Locatie_Behandelduur',\n",
    "        'Aanvraag_Laatste_Locatie_Gewenste_Aankomsttijd','Aanvraag_Laatste_Locatie_Behandelduur',\n",
    "        'Reactie_Variant', 'Reactie_Moment',\n",
    "        'Aanvraag_Treinwijzingen', 'Reactie_Toelichting', 'Reactie_Dienstregelingjaar',\n",
    "       'Reactie_Vervoerder_Afkorting', 'Reactie_Treinnummer',\n",
    "       'Aanvraag_Verwerkingdagen_Aangebodendag',\n",
    "       'Reactie_Eerste_Activiteit_Treintype',\n",
    "       'Reactie_Eerste_Activiteit_Rijkarakteristiek',\n",
    "       'Reactie_Eerste_Activiteit_BVRegelingen',\n",
    "       'Reactie_Eerste_Activiteit_Materieelsoort',\n",
    "       'Reactie_Eerste_Activiteit_Materieeltype',\n",
    "       'Reactie_Eerste_Activiteit_Tractievorm',\n",
    "       'Reactie_Eerste_Activiteit_MaxLengte',\n",
    "       'Reactie_Eerste_Activiteit_MaxSnelheid',\n",
    "       'Reactie_Eerste_Activiteit_Dienstregelingssnelheid',\n",
    "       'Reactie_Eerste_Activiteit_MaxGewicht',\n",
    "       'Reactie_Eerste_Activiteit_Remstand',\n",
    "       'Reactie_Eerste_Activiteit_RemPercentage',\n",
    "       'Reactie_Eerste_Activiteit_Belastingklasse',\n",
    "       'Reactie_Eerste_Activiteit_Profielcodes',\n",
    "       'Reactie_Eerste_Activiteit_Toelichting',\n",
    "       'Reactie_Eerste_Activiteit_Dienstregelpunt',\n",
    "       'Reactie_Eerste_Activiteit_DienstregelpuntSpoor',\n",
    "       'Reactie_Eerste_Activiteit_Treinactiviteit',\n",
    "       'Reactie_Eerste_Activiteit_Tijdstip',\n",
    "       'Reactie_Eerste_Activiteit_Tijdstip_offset',\n",
    "       'Reactie_Eerste_Activiteit_Opmerkingen',\n",
    "       'Reactie_Laatste_Activiteit_Dienstregelpunt',\n",
    "       'Reactie_Laatste_Activiteit_DienstregelpuntSpoor',\n",
    "       'Reactie_Laatste_Activiteit_Activiteitsoort',\n",
    "       'Reactie_Laatste_Activiteit_Tijdstip',\n",
    "       'Reactie_Laatste_Activiteit_Tijdstip_Offset',\n",
    "       'Reactie_Laatste_Activiteit_Opmerkingen', 'Reactie_Routelint',\n",
    "       'IngeschatteUren', 'GespendeerdeUren', 'ResterendeUren', 'Unnamed: 109'])\n",
    "\n",
    "#All reaction columns deleted except 'Reactie_type' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6e975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean[\"Number_Of_Stops_requested\"] = data_clean[\"Aanvraag_Routelint\"].str.split(\"-\").str.len() # create new column with number of stops\n",
    "data_clean[\"Aanvraag_Indienmoment\"] = pd.to_datetime(data_clean[\"Aanvraag_Indienmoment\"]) # make info in column datetime info\n",
    "data_clean[\"Aanvraag_Day\"] = data_clean[\"Aanvraag_Indienmoment\"].dt.day_name() # create new column with day of week of request \n",
    "data_clean[\"Aanvraag_time\"] = data_clean[\"Aanvraag_Indienmoment\"].dt.time # create new column with time of request\n",
    "\n",
    "#time range request first location\n",
    "data_clean[\"Aanvraag_Eerste_Locatie_Vroegste_Vertrektijd\"] = pd.to_datetime(data_clean[\"Aanvraag_Eerste_Locatie_Vroegste_Vertrektijd\"], format=\"%H:%M:%S\") #convert to time\n",
    "data_clean[\"Aanvraag_Eerste_Locatie_Laatste_Vertrektijd\"] = pd.to_datetime(data_clean[\"Aanvraag_Eerste_Locatie_Laatste_Vertrektijd\"], format=\"%H:%M:%S\") #convert to time\n",
    "data_clean[\"Aanvraag_time_range_Eerste_Locatie_Vertrektijd\"] = (data_clean['Aanvraag_Eerste_Locatie_Laatste_Vertrektijd'] - data_clean['Aanvraag_Eerste_Locatie_Vroegste_Vertrektijd']).dt.total_seconds()/60\n",
    "data_clean.loc[data_clean[\"Aanvraag_time_range_Eerste_Locatie_Vertrektijd\"] < 0,\n",
    "    \"Aanvraag_time_range_Eerste_Locatie_Vertrektijd\"] += 1440 \n",
    "\n",
    "\n",
    "\n",
    "#time range request last location\n",
    "data_clean[\"Aanvraag_Laatste_Locatie_Vroegste_Aankomsttijd\"] = pd.to_datetime(data_clean[\"Aanvraag_Laatste_Locatie_Vroegste_Aankomsttijd\"], format=\"%H:%M:%S\")#convert to time\n",
    "data_clean[\"Aanvraag_Laatste_Locatie_Laatste_Aankomsttijd\"] = pd.to_datetime(data_clean[\"Aanvraag_Laatste_Locatie_Laatste_Aankomsttijd\"], format=\"%H:%M:%S\") #convert to time\n",
    "data_clean[\"Aanvraag_time_range_Laatste_Locatie_Aankomsttijd\"] = (data_clean[\"Aanvraag_Laatste_Locatie_Laatste_Aankomsttijd\"] - data_clean[\"Aanvraag_Laatste_Locatie_Vroegste_Aankomsttijd\"]).dt.total_seconds()/60\n",
    "data_clean.loc[data_clean[\"Aanvraag_time_range_Laatste_Locatie_Aankomsttijd\"] < 0,\n",
    "    \"Aanvraag_time_range_Laatste_Locatie_Aankomsttijd\"] += 1440 \n",
    "    \n",
    "\n",
    "\n",
    "# New col for behandelingen, if stabling is needed 1, else 0\n",
    "data_clean[\"Aanvraag_Eerste_Locatie_Opstellen_True\"] = data_clean[\"Aanvraag_Eerste_Locatie_Behandelingen\"].str.contains(\"Opstellen\", na=False).astype(int)\n",
    "data_clean[\"Aanvraag_Laatste_Locatie_Opstellen_True\"] = data_clean[\"Aanvraag_Laatste_Locatie_Behandelingen\"].str.contains(\"Opstellen\", na=False).astype(int)\n",
    "\n",
    "# drop used columns\n",
    "data_clean = data_clean.drop(columns=[\"Aanvraag_Routelint\", \"Aanvraag_Eerste_Locatie_Behandelingen\", \"Aanvraag_Laatste_Locatie_Behandelingen\"])\n",
    "\n",
    "display(data_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773d9d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save new dataset as csv\n",
    "\n",
    "data_clean.to_csv(\"cleaned_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b90291",
   "metadata": {},
   "source": [
    "Numeric dataset transformation part (Encoding the features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8822a879",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b82409",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = pd.read_csv(\n",
    "    'cleaned_dataset.csv',\n",
    "    engine=\"python\", \n",
    "    sep=None           # auto-detects delimiter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9110f798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data by process type, leave only the NIEUW requests\n",
    "cleaned_data[\"Process_type\"] = cleaned_data[\"Procestype\"].map({\n",
    "    \"NIEUW\": 1,\n",
    "    \"WIJZIGING\": 0\n",
    "})\n",
    "data_NIEUW = cleaned_data[cleaned_data[\"Process_type\"] == 1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd497938",
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = \"Aanvraag_Eerste_Locatie_Vroegste_Vertrektijd\"\n",
    "\n",
    "# Ensure datetimelike\n",
    "data_NIEUW[col1] = pd.to_datetime(data_NIEUW[col1], errors=\"coerce\")\n",
    "\n",
    "# Extract hour (0–23)\n",
    "data_NIEUW[\"Hour_group\"] = data_NIEUW[col1].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b16916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out those rows without requested earliest departure time\n",
    "data_NIEUW_filtered = data_NIEUW.dropna(subset=[\"Hour_group\"]).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4879183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the hours of day in a cyclical way, sothat 0:00 is close to 23:00\n",
    "data_NIEUW_filtered[\"Hour_sin\"] = np.sin(2 * np.pi * data_NIEUW_filtered[\"Hour_group\"] / 24)\n",
    "data_NIEUW_filtered[\"Hour_cos\"] = np.cos(2 * np.pi * data_NIEUW_filtered[\"Hour_group\"] / 24)\n",
    "\n",
    "# Show example\n",
    "print(data_NIEUW_filtered[[\"Hour_group\", \"Hour_sin\", \"Hour_cos\"]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff900806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the reaction by prorail into binary numbers\n",
    "data_NIEUW_filtered[\"Approved\"] = data_NIEUW_filtered[\"Reactie_type\"].map({\n",
    "    \"AANGEBODEN\": 1,\n",
    "    \"GEEN_AANBIEDING_MOGELIJK\": 0\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a5013d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the information of stabling and time tolerance from the corresponding columns\n",
    "data_NIEUW_filtered[\"Stabling\"] = data_NIEUW_filtered[\"Aanvraag_Laatste_Locatie_Opstellen_True\"]\n",
    "data_NIEUW_filtered[\"Tolerance\"] = data_NIEUW_filtered[\"Aanvraag_time_range_Eerste_Locatie_Vertrektijd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6b2036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the days of week in a cyclical way, so that Monday is close to Sunday\n",
    "mapping = {\"Monday\":0, \"Tuesday\":1, \"Wednesday\":2, \n",
    "           \"Thursday\":3, \"Friday\":4, \"Saturday\":5, \"Sunday\":6}\n",
    "data_NIEUW_filtered[\"Day_num\"] = data_NIEUW_filtered[\"Aanvraag_Day\"].map(mapping)\n",
    "data_NIEUW_filtered[\"Day_sin\"] = np.sin(2 * np.pi * data_NIEUW_filtered[\"Day_num\"] / 7)\n",
    "data_NIEUW_filtered[\"Day_cos\"] = np.cos(2 * np.pi * data_NIEUW_filtered[\"Day_num\"] / 7)\n",
    "\n",
    "#Using OneHotEncoder to encode the origin and destination of a request\n",
    "encoder_origin = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "origin_encoded = encoder_origin.fit_transform(data_NIEUW_filtered[[\"Aanvraag_Eerste_Locatie_Dienstregelpunt\"]])\n",
    "origin_columns = encoder_origin.get_feature_names_out([\"Aanvraag_Eerste_Locatie_Dienstregelpunt\"])\n",
    "origin_df = pd.DataFrame(origin_encoded, columns=origin_columns, index=data_NIEUW_filtered.index)\n",
    "\n",
    "encoder_dest = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "dest_encoded = encoder_dest.fit_transform(data_NIEUW_filtered[[\"Aanvraag_Laatste_Locatie_Dienstregelpunt\"]])\n",
    "dest_columns = encoder_dest.get_feature_names_out([\"Aanvraag_Laatste_Locatie_Dienstregelpunt\"])\n",
    "dest_df = pd.DataFrame(dest_encoded, columns=dest_columns, index=data_NIEUW_filtered.index)\n",
    "\n",
    "# Integrate all the columns into a numeric dataset for model processing\n",
    "numeric_dataset = pd.concat([data_NIEUW_filtered[[\"Process_type\"]], \n",
    "                             data_NIEUW_filtered[[\"Stabling\"]], \n",
    "                             data_NIEUW_filtered[[\"Tolerance\"]],\n",
    "                             data_NIEUW_filtered[[\"Day_sin\"]],\n",
    "                             data_NIEUW_filtered[[\"Day_cos\"]], \n",
    "                             data_NIEUW_filtered[[\"Hour_sin\"]],\n",
    "                             data_NIEUW_filtered[[\"Hour_cos\"]],\n",
    "                             origin_df, \n",
    "                             dest_df, \n",
    "                             data_NIEUW_filtered[[\"Approved\"]]], \n",
    "                             axis=1)\n",
    "\n",
    "print(numeric_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0438d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to new CSV file\n",
    "numeric_dataset.to_csv(\"numeric_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d31243",
   "metadata": {},
   "source": [
    "Logistic Regression part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b94d7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, log_loss, brier_score_loss\n",
    "from sklearn.calibration import calibration_curve, CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ca073c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training set and test set\n",
    "numeric_data = pd.read_csv(\n",
    "    'numeric_dataset.csv',\n",
    "    engine=\"python\", \n",
    "    sep=None           # auto-detects delimiter\n",
    ")\n",
    "\n",
    "y = numeric_data['Approved'].values\n",
    "X = numeric_data.drop(columns=['Approved']).values   \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92660b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"logit\", LogisticRegression(solver=\"saga\", max_iter=5000, n_jobs=-1))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"logit__penalty\": [\"l2\", \"l1\"],\n",
    "    \"logit__C\": [0.01, 0.1, 1.0, 10.0],\n",
    "    \"logit__class_weight\": [None, \"balanced\"],   # try if classes are imbalanced\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"roc_auc\",   # ranking metric, good for probabilities\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    refit=True,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "best_clf = gs.best_estimator_\n",
    "print(\"Best params:\", gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de41af7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate probability quality\n",
    "proba_test = best_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, proba_test))\n",
    "print(\"PR AUC:\", average_precision_score(y_test, proba_test))  # useful for imbalance\n",
    "print(\"Log Loss:\", log_loss(y_test, proba_test))               # proper scoring rule\n",
    "print(\"Brier Score:\", brier_score_loss(y_test, proba_test))    # calibration-focused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93604b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual Calibration check\n",
    "frac_true, frac_pred = calibration_curve(y_test, proba_test, n_bins=10, strategy=\"quantile\")\n",
    "plt.figure()\n",
    "plt.plot(frac_pred, frac_true, marker=\"o\")\n",
    "plt.plot([0,1],[0,1],\"--\")\n",
    "plt.xlabel(\"Predicted probability\")\n",
    "plt.ylabel(\"Observed frequency\")\n",
    "plt.title(\"Calibration curve (uncalibrated)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5796c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration\n",
    "calibrated = CalibratedClassifierCV(best_clf, method=\"isotonic\", cv=5)  # or method=\"sigmoid\"\n",
    "calibrated.fit(X_train, y_train)\n",
    "\n",
    "proba_test_cal = calibrated.predict_proba(X_test)[:, 1]\n",
    "print(\"Brier (calibrated):\", brier_score_loss(y_test, proba_test_cal))\n",
    "print(\"Log Loss (calibrated):\", log_loss(y_test, proba_test_cal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609c79e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncalibrated\n",
    "frac_true_u, frac_pred_u = calibration_curve(y_test, proba_test, n_bins=10, strategy=\"quantile\")\n",
    "\n",
    "# Calibrated\n",
    "frac_true_c, frac_pred_c = calibration_curve(y_test, proba_test_cal, n_bins=10, strategy=\"quantile\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(frac_pred_u, frac_true_u, marker=\"o\", label=\"Uncalibrated\")\n",
    "plt.plot(frac_pred_c, frac_true_c, marker=\"o\", label=\"Calibrated (isotonic)\")\n",
    "plt.plot([0,1],[0,1],\"--\", label=\"Perfect\")\n",
    "plt.xlabel(\"Predicted probability\")\n",
    "plt.ylabel(\"Observed frequency\")\n",
    "plt.title(\"Calibration curve: before vs after\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7607800",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"Approved\"\n",
    "\n",
    "# 1) Feature columns (keeps original order)\n",
    "feature_cols = numeric_data.drop(columns=[target_col]).columns.tolist()\n",
    "\n",
    "# 2) Train split using those columns\n",
    "X = numeric_data[feature_cols].to_numpy()\n",
    "y = numeric_data[target_col].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca80355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the calibrated model\n",
    "import joblib, sklearn, json, time\n",
    "\n",
    "artifact = {\n",
    "    \"model\": calibrated,                    # or best_clf if you’re not using calibration\n",
    "    \"feature_cols\": feature_cols,           # exact training column order\n",
    "    \"sklearn_version\": sklearn.__version__,\n",
    "    \"created_at\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "}\n",
    "\n",
    "joblib.dump(artifact, \"logit_calibrated.joblib\", compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b22673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect coefficients\n",
    "coef = best_clf.named_steps[\"logit\"].coef_.ravel()\n",
    "intercept = best_clf.named_steps[\"logit\"].intercept_[0]\n",
    "coef_df = pd.DataFrame({\n",
    "    \"feature\": feature_cols,\n",
    "    \"coef\": coef,\n",
    "    \"odds_ratio\": np.exp(coef)\n",
    "}).sort_values(\"coef\", ascending=False)\n",
    "coef_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mude-week-2-6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
